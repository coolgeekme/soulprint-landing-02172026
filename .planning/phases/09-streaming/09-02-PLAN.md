---
phase: 09-streaming
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/chat/page.tsx
  - components/chat/telegram-chat-v2.tsx
autonomous: true

must_haves:
  truths:
    - "User can click a stop button during AI generation and the response halts with partial text preserved"
    - "Stop button appears in place of send button while AI is generating"
    - "Partial response text remains visible in the chat after stopping"
    - "User can send a new message after stopping generation"
    - "Frontend handles AbortError gracefully without showing error messages"
  artifacts:
    - path: "app/chat/page.tsx"
      provides: "AbortController integration for stop functionality"
      contains: "AbortController"
    - path: "components/chat/telegram-chat-v2.tsx"
      provides: "Stop button UI and isGenerating prop"
      contains: "onStop"
  key_links:
    - from: "app/chat/page.tsx"
      to: "AbortController"
      via: "ref stored during fetch, abort() called on stop"
      pattern: "abortControllerRef"
    - from: "components/chat/telegram-chat-v2.tsx"
      to: "app/chat/page.tsx"
      via: "onStop callback prop and isGenerating prop"
      pattern: "onStop|isGenerating"
    - from: "app/chat/page.tsx"
      to: "/api/chat"
      via: "fetch with signal parameter"
      pattern: "signal.*controller\\.signal|signal.*abort"
---

<objective>
Add stop/cancel functionality to the chat frontend so users can halt AI response generation mid-stream.

Purpose: When streaming responses, users need the ability to stop a long or unwanted response. This implements STRM-02 (stop/cancel) and completes the streaming UX by adding AbortController to the fetch call and a stop button to the chat UI.

Output: Updated `app/chat/page.tsx` with AbortController integration and `components/chat/telegram-chat-v2.tsx` with a stop button that replaces the send button during generation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-streaming/09-RESEARCH.md
@app/chat/page.tsx
@components/chat/telegram-chat-v2.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add AbortController and isGenerating state to chat page</name>
  <files>app/chat/page.tsx</files>
  <action>
Modify `app/chat/page.tsx` to support stopping generation mid-stream:

1. **Add new state and ref:**
```typescript
const [isGenerating, setIsGenerating] = useState(false);
const abortControllerRef = useRef<AbortController | null>(null);
```

2. **Modify `processMessage` function** (the regular chat flow section starting around line 386):
   - Before the `fetch('/api/chat', ...)` call, create a new AbortController and store it:
   ```typescript
   const controller = new AbortController();
   abortControllerRef.current = controller;
   setIsGenerating(true);
   ```
   - Add `signal: controller.signal` to the fetch options object (alongside method, headers, body)
   - In the catch block, add handling for AbortError:
   ```typescript
   } catch (error) {
     if (error instanceof Error && error.name === 'AbortError') {
       // User stopped generation -- partial response is already in messages state
       // Don't show error message, just log
       console.log('Generation stopped by user');
     } else {
       console.error('Chat error:', error);
       setMessages(prev => [...prev, {
         id: (Date.now() + 1).toString(),
         role: 'assistant',
         content: "Sorry, something went wrong. Try again?",
         timestamp: new Date(),
       }]);
     }
   }
   ```
   - In the finally/cleanup (after try-catch), add:
   ```typescript
   setIsGenerating(false);
   abortControllerRef.current = null;
   ```
   - IMPORTANT: Also save the partial response when user aborts. After the stream reading while-loop completes (or on abort), save whatever `responseContent` has accumulated:
   ```typescript
   // After the while loop (which breaks on done OR on AbortError caught in outer catch)
   if (responseContent) {
     saveMessage('assistant', responseContent);
     // ... existing AI name refresh logic
   }
   ```
   Move the saveMessage + name refresh into a finally block or ensure it runs whether the stream completes normally or is aborted. The key insight: when abort happens, the `reader.read()` call will throw AbortError, so `responseContent` holds whatever was accumulated up to that point. Save it before the error propagates.

   A clean pattern:
   ```typescript
   try {
     // ... fetch, create reader, read loop ...
     while (true) {
       const { done, value } = await reader.read();
       if (done) break;
       // ... parse chunks, accumulate responseContent ...
     }
   } catch (error) {
     if (error instanceof Error && error.name === 'AbortError') {
       console.log('Generation stopped by user');
     } else {
       throw error; // Re-throw non-abort errors
     }
   } finally {
     // Save whatever we accumulated (full or partial)
     if (responseContent) {
       saveMessage('assistant', responseContent);
       // AI name refresh if needed (existing logic)
     }
     setIsGenerating(false);
     abortControllerRef.current = null;
   }
   ```

3. **Add handleStop callback:**
```typescript
const handleStop = useCallback(() => {
  if (abortControllerRef.current) {
    abortControllerRef.current.abort();
    // isGenerating will be set to false in the finally block of processMessage
  }
}, []);
```

4. **Pass new props to TelegramChatV2:**
```tsx
<TelegramChatV2
  messages={messages}
  onSendMessage={handleSendMessage}
  onStop={handleStop}
  isLoading={isLoading}
  isGenerating={isGenerating}
  isDeepSearching={isDeepSearching}
  aiName={aiName}
  aiAvatar={aiAvatar || undefined}
  onBack={handleBack}
  onSettings={() => setShowSettings(true)}
/>
```

5. **Update the processQueue function:** The `setIsLoading(true/false)` calls in `processQueue` should continue as-is. `isGenerating` is separate from `isLoading` -- isLoading means "queue is processing", isGenerating means "stream is active right now". The stop button shows when isGenerating is true.

**What NOT to do:**
- Do NOT change the message queue logic or processQueue mutex pattern
- Do NOT remove existing naming mode, rename, or task handling logic
- Do NOT change the SSE parsing logic (it already handles incremental `data:` lines correctly)
- Do NOT add the `setIsDeepSearching(false)` in the finally block -- it's already handled at the end of processMessage
  </action>
  <verify>
Run `npm run build` to confirm no TypeScript errors. Check that:
- `grep -n "AbortController" app/chat/page.tsx` shows controller usage
- `grep -n "isGenerating" app/chat/page.tsx` shows state management
- `grep -n "handleStop" app/chat/page.tsx` shows stop handler
- `grep -n "signal" app/chat/page.tsx` shows signal passed to fetch
  </verify>
  <done>
Chat page creates AbortController before each chat fetch, passes signal to the request, handles AbortError gracefully (no error message shown), saves partial response on stop, and exposes isGenerating state and handleStop callback to the UI component.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add stop button to chat UI component</name>
  <files>components/chat/telegram-chat-v2.tsx</files>
  <action>
Modify `components/chat/telegram-chat-v2.tsx` to show a stop button during generation:

1. **Update the interface to accept new props:**
```typescript
interface TelegramChatV2Props {
  messages: Message[];
  onSendMessage: (content: string, voiceVerified?: boolean, deepSearch?: boolean) => void;
  onStop?: () => void;           // NEW
  isLoading?: boolean;
  isGenerating?: boolean;        // NEW
  isDeepSearching?: boolean;
  aiName?: string;
  aiAvatar?: string;
  onBack?: () => void;
  onSettings?: () => void;
}
```

2. **Destructure the new props in the component:**
```typescript
export function TelegramChatV2({
  messages,
  onSendMessage,
  onStop,              // NEW
  isLoading = false,
  isGenerating = false, // NEW
  isDeepSearching = false,
  aiName = 'SoulPrint',
  aiAvatar,
  onBack,
  onSettings,
}: TelegramChatV2Props) {
```

3. **Add Square icon import** (for the stop button):
```typescript
import { ArrowLeft, Mic, Send, Moon, Sun, LogOut, Search, Square } from 'lucide-react';
```

4. **Update the loading indicator** (lines ~413-442). Replace the current loading indicator with one that also handles the generating state. When `isGenerating` is true, we do NOT show the bouncing dots (because the message content is already streaming into the message bubble). The loading dots should only show when `isLoading && !isGenerating` (i.e., waiting for the initial response before any chunks arrive). Actually, more precisely: show loading dots when `isLoading` AND the last message is NOT an empty/streaming assistant message. But the simplest approach: show loading indicator only when `isLoading && !isGenerating`:

```tsx
{/* Loading indicator - only when waiting, not during active streaming */}
{isLoading && !isGenerating && (
  <div className="flex justify-start">
    <div className="rounded-[16px_16px_16px_4px] px-4 py-3 shadow-sm bg-muted transition-colors">
      {isDeepSearching ? (
        <div className="flex items-center gap-2">
          <Search className="w-4 h-4 animate-pulse text-primary" />
          <span className="text-sm text-muted-foreground">
            Researching...
          </span>
        </div>
      ) : (
        <div className="flex gap-1">
          <span className="w-2 h-2 rounded-full bg-muted-foreground animate-bounce" style={{ animationDelay: '0ms' }} />
          <span className="w-2 h-2 rounded-full bg-muted-foreground animate-bounce" style={{ animationDelay: '150ms' }} />
          <span className="w-2 h-2 rounded-full bg-muted-foreground animate-bounce" style={{ animationDelay: '300ms' }} />
        </div>
      )}
    </div>
  </div>
)}
```

5. **Update the send/mic button area** (lines ~494-517). Add a third state: when `isGenerating` is true, show a stop button instead of send or mic:

```tsx
{/* Send/Stop/Mic Button */}
{isGenerating ? (
  /* Stop button - shown during active generation */
  <button
    type="button"
    onClick={onStop}
    className="flex-shrink-0 w-11 h-11 flex items-center justify-center rounded-full bg-muted-foreground/20 transition-colors active:opacity-70"
    aria-label="Stop generating"
  >
    <Square className="w-4 h-4 fill-current text-foreground" />
  </button>
) : input.trim() ? (
  <button
    type="submit"
    className="flex-shrink-0 w-11 h-11 flex items-center justify-center rounded-full bg-primary transition-colors active:opacity-70"
  >
    <Send className="w-5 h-5 text-white" />
  </button>
) : (
  <button
    type="button"
    onClick={handleMicClick}
    disabled={isTranscribing}
    className={`flex-shrink-0 w-11 h-11 flex items-center justify-center rounded-full transition-all active:opacity-70 ${
      isRecording ? 'animate-pulse text-red-500 bg-red-500/10' : 'text-muted-foreground bg-transparent'
    }`}
  >
    {isTranscribing ? (
      <div className="w-5 h-5 border-2 border-current border-t-transparent rounded-full animate-spin" />
    ) : (
      <Mic className="w-6 h-6" />
    )}
  </button>
)}
```

6. **Remove the `disabled={isLoading}` from the send button** (was on old send button). Users should be able to queue messages even during loading (existing queue mechanism). The send button should NOT be disabled.

7. **Update the header subtitle** to show "typing..." during generation instead of "online":
```tsx
<span className="text-[13px] text-muted-foreground transition-colors">
  {isGenerating ? 'typing...' : 'online'}
</span>
```

**What NOT to do:**
- Do NOT change the SwipeableMessage component
- Do NOT change the voice recording logic
- Do NOT change the deep search toggle
- Do NOT add animations beyond what's described (keep it simple)
- Do NOT change the message rendering or MessageContent component
  </action>
  <verify>
Run `npm run build` to confirm no TypeScript errors. Check that:
- `grep -n "onStop" components/chat/telegram-chat-v2.tsx` shows the prop and its usage
- `grep -n "isGenerating" components/chat/telegram-chat-v2.tsx` shows the prop and conditional rendering
- `grep -n "Square" components/chat/telegram-chat-v2.tsx` shows the stop icon import and usage
- `grep -n "typing" components/chat/telegram-chat-v2.tsx` shows the header status update
  </verify>
  <done>
Chat UI shows a stop button (filled square icon) in place of the send/mic button when AI is actively generating. Header shows "typing..." during generation. Loading dots only show during the pre-streaming wait period. Stop button calls onStop which triggers AbortController.abort() in the parent.
  </done>
</task>

</tasks>

<verification>
1. `npm run build` passes with no errors
2. Stop button appears in TelegramChatV2 when isGenerating is true
3. AbortController is created for each chat fetch in page.tsx
4. fetch signal is connected to the AbortController
5. AbortError is caught without showing error toast to user
6. Partial response is saved to chat history on stop
7. Header shows "typing..." during generation
</verification>

<success_criteria>
- Stop button (square icon) appears during AI generation, replacing send/mic button
- Clicking stop triggers AbortController.abort() which cancels the fetch
- Partial response text remains visible in chat (not removed)
- Partial response is saved via saveMessage
- User can immediately send a new message after stopping
- No error message shown to user when they stop generation
- Header shows "typing..." during generation, "online" otherwise
- Loading dots only appear during initial wait (not during active streaming)
- `npm run build` passes
</success_criteria>

<output>
After completion, create `.planning/phases/09-streaming/09-02-SUMMARY.md`
</output>
