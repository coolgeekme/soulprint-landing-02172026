---
phase: 03-web-search-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/search/citation-validator.ts
  - lib/search/citation-formatter.ts
  - app/api/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "Citations from web search APIs are validated for reachability before being passed to the LLM"
    - "Invalid or unreachable URLs are filtered out and logged with error reasons"
    - "User receives only validated, reachable citations in responses"
    - "Domain names are extracted from valid URLs for frontend display"
  artifacts:
    - path: "lib/search/citation-validator.ts"
      provides: "validateCitations function with HEAD request validation and SSRF protection"
      min_lines: 80
    - path: "lib/search/citation-formatter.ts"
      provides: "extractDomain and formatCitationsForDisplay utilities"
      min_lines: 30
    - path: "app/api/chat/route.ts"
      provides: "Citation validation integrated between smartSearch and prompt building"
      contains: "validateCitations"
  key_links:
    - from: "app/api/chat/route.ts"
      to: "lib/search/citation-validator.ts"
      via: "Call validateCitations() on searchResult.citations before using in prompt"
      pattern: "validateCitations\\(.*citations"
    - from: "lib/search/citation-validator.ts"
      to: "external URLs"
      via: "HEAD requests with AbortController timeout and SSRF blocking"
      pattern: "fetch.*HEAD.*AbortController"
---

<objective>
Implement backend citation validation to verify web search URLs are reachable before showing them to users, preventing hallucinated or broken citations from appearing in chat responses.

Purpose: Currently, citations from Perplexity/Tavily flow directly into the system prompt without validation. If URLs are unreachable (404, timeout) or if the LLM invents citations, users see broken sources. This plan validates citations between search and prompt construction, filters out invalid URLs, and extracts domain names for clean display.

Output: Working citation validation pipeline that accepts only reachable URLs, with domain extraction utilities ready for frontend integration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-web-search-validation/03-RESEARCH.md
@lib/search/smart-search.ts
@app/api/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Citation Validator Module</name>
  <files>lib/search/citation-validator.ts</files>
  <action>
Create a new file `lib/search/citation-validator.ts` that validates URL reachability using HEAD requests with timeout and SSRF protection.

**Create the file with these exports:**

```typescript
/**
 * Citation Validator - Verify web search citations are reachable
 *
 * Features:
 * - Parallel validation with Promise.allSettled
 * - HEAD requests (no body download)
 * - 3s timeout per URL
 * - SSRF protection (blocks localhost/internal IPs)
 * - Accepts 2xx and 3xx status codes (follow redirects)
 */

export interface ValidationResult {
  valid: string[];
  invalid: string[];
  errors: Record<string, string>; // url -> error reason
}

export interface ValidationOptions {
  timeout?: number; // Default 3000ms
}

/**
 * Validate multiple citations in parallel
 */
export async function validateCitations(
  urls: string[],
  options: ValidationOptions = {}
): Promise<ValidationResult> {
  const { timeout = 3000 } = options;

  const valid: string[] = [];
  const invalid: string[] = [];
  const errors: Record<string, string> = {};

  // Validate in parallel with Promise.allSettled (no fail-fast)
  const results = await Promise.allSettled(
    urls.map(url => validateSingleCitation(url, timeout))
  );

  results.forEach((result, i) => {
    const url = urls[i];
    if (result.status === 'fulfilled' && result.value.valid) {
      valid.push(url);
    } else {
      invalid.push(url);
      errors[url] = result.status === 'rejected'
        ? String(result.reason)
        : result.value.error || 'Unknown error';
    }
  });

  return { valid, invalid, errors };
}

/**
 * Validate a single citation URL
 */
async function validateSingleCitation(
  url: string,
  timeout: number
): Promise<{ valid: boolean; error?: string }> {
  // Step 1: URL format check
  let parsed: URL;
  try {
    parsed = new URL(url);
  } catch {
    return { valid: false, error: 'Invalid URL format' };
  }

  // Step 2: SSRF protection - block internal/private IPs
  const hostname = parsed.hostname.toLowerCase();

  // Block localhost
  if (hostname === 'localhost' || hostname === '127.0.0.1') {
    return { valid: false, error: 'Localhost blocked (SSRF)' };
  }

  // Block private IPv4 ranges (192.168.x.x, 10.x.x.x, 172.16-31.x.x)
  if (
    hostname.startsWith('192.168.') ||
    hostname.startsWith('10.') ||
    /^172\.(1[6-9]|2\d|3[01])\./.test(hostname)
  ) {
    return { valid: false, error: 'Private IP blocked (SSRF)' };
  }

  // Block IPv6 localhost
  if (hostname === '::1' || hostname === '[::1]') {
    return { valid: false, error: 'IPv6 localhost blocked (SSRF)' };
  }

  // Step 3: HEAD request with timeout
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  try {
    const response = await fetch(url, {
      method: 'HEAD',
      signal: controller.signal,
      headers: {
        'User-Agent': 'SoulPrint/2.1 (Citation Validator)',
      },
      redirect: 'follow', // Follow HTTP->HTTPS, www->non-www
    });

    clearTimeout(timeoutId);

    // Accept 2xx (OK) and 3xx (redirects)
    if (response.ok || (response.status >= 300 && response.status < 400)) {
      return { valid: true };
    }

    return { valid: false, error: `HTTP ${response.status}` };

  } catch (error) {
    clearTimeout(timeoutId);

    if (error instanceof Error) {
      if (error.name === 'AbortError') {
        return { valid: false, error: 'Timeout (>3s)' };
      }
      return { valid: false, error: `Network error: ${error.message}` };
    }

    return { valid: false, error: 'Unknown network error' };
  }
}
```

**Key implementation notes:**
- Use `Promise.allSettled()` not `Promise.all()` — we want to validate ALL URLs even if some fail
- HEAD requests only — no body download, just check if URL exists
- AbortController for timeout — prevent hanging on slow/dead URLs
- SSRF protection first — block internal IPs before making any requests
- Accept both 2xx and 3xx — many sites redirect HTTP->HTTPS, treat as valid
- User-Agent header — identify ourselves to avoid bot blocking
  </action>
  <verify>
Run `npx tsc --noEmit` to verify TypeScript compilation. Check exports with: `grep -E "^export (interface|async function)" lib/search/citation-validator.ts` — should see ValidationResult, ValidationOptions, and validateCitations.
  </verify>
  <done>
File lib/search/citation-validator.ts exists with validateCitations function, SSRF protection, HEAD request validation, and timeout handling. TypeScript compiles without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Citation Formatter Module</name>
  <files>lib/search/citation-formatter.ts</files>
  <action>
Create a new file `lib/search/citation-formatter.ts` for domain extraction and citation metadata formatting.

**Create the file with these exports:**

```typescript
/**
 * Citation Formatter - Extract clean domain names for display
 *
 * Features:
 * - Extract domain from URL (remove www., keep subdomain)
 * - Format citations with metadata for frontend
 * - Handle invalid URLs gracefully
 */

export interface CitationMetadata {
  url: string;
  domain: string;
  title?: string; // From search API if available (Tavily provides titles)
}

/**
 * Extract clean domain name from URL for display
 *
 * Examples:
 * - https://www.nytimes.com/article -> nytimes.com
 * - https://blog.example.com/post -> blog.example.com
 * - https://example.com:8080/path -> example.com
 */
export function extractDomain(url: string): string {
  try {
    const parsed = new URL(url);
    // Remove www. prefix but keep other subdomains
    return parsed.hostname.replace(/^www\./, '');
  } catch {
    // If URL parsing fails, return the original URL
    // (should never happen if citation passed validation)
    return url;
  }
}

/**
 * Format citations with metadata for frontend display
 *
 * @param citations - Array of validated URLs
 * @param titles - Optional titles from search API (same order as citations)
 * @returns Array of citation metadata objects
 */
export function formatCitationsForDisplay(
  citations: string[],
  titles?: string[]
): CitationMetadata[] {
  return citations.map((url, i) => ({
    url,
    domain: extractDomain(url),
    title: titles?.[i],
  }));
}
```

**Key implementation notes:**
- `extractDomain` uses `new URL().hostname` — robust, handles ports, IPv6, etc.
- Remove `www.` but keep other subdomains (e.g., `blog.example.com` stays as-is)
- Graceful fallback if URL parsing fails (return original URL)
- `formatCitationsForDisplay` optional titles parameter — Tavily provides titles, Perplexity doesn't
- Simple, focused utilities — no over-engineering
  </action>
  <verify>
Run `npx tsc --noEmit` to verify TypeScript compilation. Test domain extraction with: `node -e "const {extractDomain} = require('./lib/search/citation-formatter'); console.log(extractDomain('https://www.nytimes.com/article'))"` — should output "nytimes.com".
  </verify>
  <done>
File lib/search/citation-formatter.ts exists with extractDomain and formatCitationsForDisplay functions. TypeScript compiles without errors.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate Citation Validation in Chat Route</name>
  <files>app/api/chat/route.ts</files>
  <action>
Integrate citation validation into the chat API route between smartSearch and prompt building.

**Step 1: Add imports at top of file (around line 15-25):**
```typescript
import { validateCitations } from '@/lib/search/citation-validator';
import { formatCitationsForDisplay } from '@/lib/search/citation-formatter';
```

**Step 2: Update web search integration (around lines 305-326, after smartSearch call):**

Find the block after `searchResult = await smartSearch(...)` and REPLACE the section that handles `searchResult.performed` with:

```typescript
if (searchResult.performed) {
  // WSRV-01: Validate citations before passing to LLM
  const validation = await validateCitations(searchResult.citations, {
    timeout: 3000
  });

  // WSRV-02: Filter out invalid/unreachable citations
  if (validation.invalid.length > 0) {
    reqLog.warn({
      total: searchResult.citations.length,
      valid: validation.valid.length,
      invalid: validation.invalid.length,
      errors: validation.errors
    }, 'Citations validated - some filtered');
  }

  // Only use validated citations for system prompt
  webSearchCitations = validation.valid;
  webSearchContext = searchResult.context;

  reqLog.info({
    source: searchResult.source,
    reason: searchResult.reason,
    originalCount: searchResult.citations.length,
    validatedCount: validation.valid.length,
    filteredCount: validation.invalid.length
  }, 'Smart search performed with citation validation');
} else if (searchResult.needed) {
  // Search was needed but failed
  reqLog.warn({
    reason: searchResult.reason,
    error: searchResult.error
  }, 'Smart search needed but failed');
} else {
  // Search not needed - static knowledge is fine
  reqLog.debug({ reason: searchResult.reason }, 'Smart search skipped');
}
```

**What changes:**
- Call `validateCitations()` immediately after `searchResult.performed`
- Log validation results (total, valid, invalid) for debugging
- Use `validation.valid` instead of `searchResult.citations` for `webSearchCitations`
- Preserve search context even if some citations are invalid
- Enhanced logging shows original count vs validated count

**What NOT to change:**
- Do NOT modify smartSearch call — validation happens AFTER search, not during
- Do NOT modify Bedrock/RLM query logic — they receive validated citations via webSearchCitations variable
- Do NOT modify error handling — validation errors are logged but don't block response
- Do NOT add citation metadata to SSE stream yet — that's Plan 2 (frontend display)
  </action>
  <verify>
Run `npx tsc --noEmit` to verify TypeScript compilation. Grep for validation integration: `grep -A 5 "validateCitations.*searchResult.citations" app/api/chat/route.ts` — should find the validation call. Check that webSearchCitations assignment uses `validation.valid`.
  </verify>
  <done>
app/api/chat/route.ts imports citation validator and formatter, calls validateCitations() on searchResult.citations, filters out invalid URLs, and only passes valid citations to the LLM via webSearchCitations variable. Logging shows validation metrics.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no TypeScript errors
2. `lib/search/citation-validator.ts` exports validateCitations function with correct signature
3. `lib/search/citation-formatter.ts` exports extractDomain and formatCitationsForDisplay
4. `app/api/chat/route.ts` imports and calls validateCitations after smartSearch
5. Grep confirms webSearchCitations uses validation.valid instead of raw searchResult.citations
6. Validation includes SSRF protection (blocks localhost, private IPs)
7. Validation uses HEAD requests with 3s timeout (no body download)
8. Promise.allSettled ensures all URLs are validated in parallel
</verification>

<success_criteria>
- Citation validation module exists with HEAD request validation, SSRF protection, and timeout handling
- Domain extraction utilities exist and handle edge cases (ports, subdomains, www removal)
- Chat API route validates citations between search and prompt building
- Invalid/unreachable citations are filtered out before passing to LLM
- Validation errors are logged with specific reasons (timeout, HTTP 404, SSRF, etc.)
- Only validated citations appear in system prompt (LLM never sees invalid URLs)
- All TypeScript code compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-web-search-validation/03-01-SUMMARY.md`
</output>
