---
phase: 01-pipeline-reliability
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rlm-service/processors/full_pass.py
  - rlm-service/processors/fact_extractor.py
  - rlm-service/processors/memory_generator.py
  - rlm-service/processors/streaming_import.py
autonomous: true

must_haves:
  truths:
    - "Chunk save failures raise exceptions that propagate to the full pass orchestrator"
    - "Fact extraction retries failed chunks up to 3 times with exponential backoff before giving up"
    - "Fact extraction concurrency is 3-5, not 10"
    - "MEMORY section is validated before save — placeholder/fallback content triggers retry"
    - "MEMORY generation retries up to 2 times before accepting fallback"
    - "Full pass timeout updates full_pass_status='failed' in the database (not just printed)"
  artifacts:
    - path: "rlm-service/processors/full_pass.py"
      provides: "Chunk save with error propagation"
      contains: "raise"
    - path: "rlm-service/processors/fact_extractor.py"
      provides: "Retry logic with exponential backoff"
      contains: "backoff"
    - path: "rlm-service/processors/memory_generator.py"
      provides: "Memory validation and retry"
      contains: "validate_memory"
    - path: "rlm-service/processors/streaming_import.py"
      provides: "Timeout error updates full_pass_status to failed in database"
      contains: "full_pass_status.*failed"
  key_links:
    - from: "rlm-service/processors/full_pass.py"
      to: "save_chunks_batch"
      via: "raises on HTTP error instead of logging"
      pattern: "raise.*save.*fail"
    - from: "rlm-service/processors/fact_extractor.py"
      to: "extract_facts_from_chunk"
      via: "retry with backoff on API errors"
      pattern: "retry|backoff"
    - from: "rlm-service/processors/memory_generator.py"
      to: "generate_memory_section"
      via: "validates output before returning"
      pattern: "validate_memory|_is_placeholder"
    - from: "rlm-service/processors/streaming_import.py"
      to: "rlm-service/processors/full_pass.py"
      via: "trigger_full_pass catches errors from run_full_pass_pipeline and updates DB"
      pattern: "full_pass_status.*failed"
---

<objective>
Make the RLM full pass pipeline fail loudly instead of silently swallowing errors. Fix chunk saves (PIPE-01), fact extraction (PIPE-02), and memory generation (PIPE-03) to be reliable.

Purpose: The full pass pipeline currently has three categories of silent failure: chunk saves return success even when HTTP POST fails, fact extraction silently returns empty facts on API errors with no retry, and memory generation falls back to placeholder content without retrying. These failures mean users end up with empty conversation_chunks, missing facts, and "No data yet." memory sections — defeating the purpose of the full pass entirely.

Output: Reliable full pass pipeline where errors propagate, retries are attempted, and placeholder content is rejected.
</objective>

<execution_context>
@/home/drewpullen/.claude/get-shit-done/workflows/execute-plan.md
@/home/drewpullen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@rlm-service/processors/full_pass.py
@rlm-service/processors/fact_extractor.py
@rlm-service/processors/memory_generator.py
@rlm-service/processors/streaming_import.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Make chunk saves and fact extraction fail loudly with retry, fix timeout DB update</name>
  <files>rlm-service/processors/full_pass.py, rlm-service/processors/fact_extractor.py, rlm-service/processors/streaming_import.py</files>
  <action>
**full_pass.py — PIPE-01: Error propagation in save_chunks_batch()**

1. Change `save_chunks_batch()` to RAISE on HTTP errors instead of just printing warnings:
   - After the Supabase POST, if `response.status_code not in (200, 201)`, raise `RuntimeError(f"Failed to save chunk batch ({response.status_code}): {response.text[:200]}")`
   - Remove the outer try/except that catches all exceptions (line 57 and 115-116). Let errors propagate to the caller.
   - Keep the inner try/except for `is_recent` date parsing (line 80-84) since that's just data enrichment.

2. In `run_full_pass_pipeline()`, do NOT add a try/except — let errors propagate naturally. The caller (`trigger_full_pass()` in streaming_import.py) already has a try/except that catches all exceptions and updates `full_pass_status='failed'` in the database (lines 243-263). Adding try/except here would be redundant. The RuntimeError from `save_chunks_batch()` will naturally propagate through `run_full_pass_pipeline()` up to `trigger_full_pass()`.

3. Also fix `delete_user_chunks()` — change from best-effort to error-raising. If delete fails, the subsequent insert will fail with duplicate key errors anyway. Remove the outer try/except, raise on non-200/204 status.

**streaming_import.py — PIPE-04: Fix timeout case not updating database**

4. In `trigger_full_pass()` (line 239-242), the `asyncio.TimeoutError` handler currently only prints a log but does NOT update the database. Fix this: add the same database update as the generic Exception handler (lines 247-263). After the print on line 241, add:
   ```python
   except asyncio.TimeoutError:
       error_msg = f"Full pass timed out after {FULL_PASS_TIMEOUT_SECONDS}s"
       print(f"[streaming_import] TIMEOUT: {error_msg} for user {user_id}")
       try:
           async with httpx.AsyncClient() as client:
               await client.patch(
                   f"{SUPABASE_URL}/rest/v1/user_profiles?user_id=eq.{user_id}",
                   json={
                       "full_pass_status": "failed",
                       "full_pass_error": error_msg,
                   },
                   headers={
                       "apikey": SUPABASE_SERVICE_KEY,
                       "Authorization": f"Bearer {SUPABASE_SERVICE_KEY}",
                       "Content-Type": "application/json",
                       "Prefer": "return=minimal",
                   },
               )
       except Exception:
           pass
   ```
   This ensures ALL failure paths (timeout AND exceptions) update `full_pass_status='failed'` in the database, so the chat UI can show the error to the user.

**fact_extractor.py — PIPE-02: Retry with backoff, reduced concurrency**

4. Add a retry wrapper function `_extract_with_retry()` that wraps `extract_facts_from_chunk()`:
   ```python
   async def _extract_with_retry(chunk_content: str, anthropic_client, max_retries: int = 3) -> dict:
       """Extract facts with exponential backoff retry on API errors."""
       empty_facts = {"preferences": [], "projects": [], "dates": [], "beliefs": [], "decisions": []}
       last_error = None
       for attempt in range(max_retries):
           try:
               return await extract_facts_from_chunk(chunk_content, anthropic_client)
           except Exception as e:
               last_error = e
               if attempt < max_retries - 1:
                   wait = (2 ** attempt) + (random.random() * 0.5)  # 1s, 2.5s, 5s with jitter
                   print(f"[FactExtractor] Retry {attempt+1}/{max_retries} after {wait:.1f}s: {e}")
                   await asyncio.sleep(wait)
       print(f"[FactExtractor] All {max_retries} retries failed: {last_error}")
       return empty_facts
   ```
   Add `import random` at the top.

5. Modify `extract_facts_from_chunk()` to RAISE on API errors instead of returning empty_facts:
   - The outer except (line 109-111) should re-raise rate limit errors (`anthropic.RateLimitError`) and `anthropic.APIError` so the retry wrapper can handle them.
   - JSON parse errors should still return empty_facts (not worth retrying — the model just gave bad output).
   - Keep the empty response check returning empty_facts (no point retrying empty responses).

6. In `extract_facts_parallel()`:
   - Change default `concurrency` parameter from 10 to 5.
   - Change the `extract_with_limit` inner function to call `_extract_with_retry()` instead of `extract_facts_from_chunk()` directly.

7. Also add `import anthropic` at the top of fact_extractor.py for the exception types.
  </action>
  <verify>
Verify by reading the modified files:
- `save_chunks_batch()` no longer has outer try/except, raises RuntimeError on non-200/201
- `delete_user_chunks()` raises on non-200/204
- `run_full_pass_pipeline()` has NO try/except (errors propagate naturally to trigger_full_pass)
- `trigger_full_pass()` TimeoutError handler now updates DB with full_pass_status='failed'
- `extract_facts_parallel()` default concurrency is 5
- `_extract_with_retry()` function exists with exponential backoff
- `extract_facts_from_chunk()` re-raises API errors
- `import random` and `import anthropic` present
  </verify>
  <done>
Chunk saves fail loudly on HTTP errors. Fact extraction retries up to 3 times with exponential backoff. Concurrency reduced from 10 to 5. All error paths in trigger_full_pass() (timeout + exceptions) update full_pass_status='failed' in database.
  </done>
</task>

<task type="auto">
  <name>Task 2: Validate MEMORY section before save and retry on failure</name>
  <files>rlm-service/processors/memory_generator.py</files>
  <action>
**memory_generator.py — PIPE-03: Validate and retry memory generation**

1. Add a validation function `_is_placeholder_memory(memory_md: str) -> bool` that detects fallback/placeholder content:
   ```python
   def _is_placeholder_memory(memory_md: str) -> bool:
       """Check if memory content is placeholder/fallback rather than real generated content."""
       placeholder_signals = [
           "Memory generation failed",
           "No data yet.",
           "Facts extracted but not yet organized",
       ]
       # Check for placeholder signals
       signal_count = sum(1 for signal in placeholder_signals if signal in memory_md)
       if signal_count >= 2:
           return True
       # Check for suspiciously short content (real memory should be >200 chars)
       if len(memory_md.strip()) < 200:
           return True
       # Check that at least one section has real content (not just headers)
       lines = [l.strip() for l in memory_md.split('\n') if l.strip() and not l.strip().startswith('#')]
       content_lines = [l for l in lines if len(l) > 20 and not l.startswith('-')]
       bullet_lines = [l for l in lines if l.startswith('- ') and len(l) > 10]
       if len(content_lines) + len(bullet_lines) < 3:
           return True
       return False
   ```

2. Modify `generate_memory_section()` to retry and validate:
   - Add parameters `max_retries: int = 2` to the function signature.
   - After getting the response text (line 80), call `_is_placeholder_memory(memory_md)`.
   - If it IS placeholder content, log a warning and retry (up to max_retries).
   - Only fall back to `_fallback_memory()` if ALL retries produce placeholder content.
   - On the final fallback, add a `[FALLBACK]` prefix to the fallback memory text so it's identifiable in the database.
   - Structure:
     ```python
     for attempt in range(max_retries + 1):
         try:
             # existing API call logic
             memory_md = response.content[0].text
             if not _is_placeholder_memory(memory_md):
                 return memory_md
             print(f"[MemoryGenerator] Attempt {attempt+1}: placeholder content detected, retrying...")
         except Exception as e:
             print(f"[MemoryGenerator] Attempt {attempt+1} error: {e}")
             if attempt == max_retries:
                 return _fallback_memory(consolidated_facts)
     # All attempts produced placeholder
     return _fallback_memory(consolidated_facts)
     ```

3. Update `_fallback_memory()` to prepend `[FALLBACK] ` to the first line so it's identifiable:
   ```python
   return f"""[FALLBACK] # MEMORY
   ...
   ```
  </action>
  <verify>
Verify by reading the modified file:
- `_is_placeholder_memory()` function exists and checks for placeholder signals, short content, and lack of real bullet points
- `generate_memory_section()` has retry loop with `max_retries` parameter
- Fallback memory starts with `[FALLBACK]` prefix
- Placeholder detection catches "No data yet." and "Memory generation failed"
  </verify>
  <done>
MEMORY section validated before save. Placeholder content triggers retry (up to 2 retries). Fallback content is clearly marked with [FALLBACK] prefix for identification.
  </done>
</task>

</tasks>

<verification>
1. Read `full_pass.py` — `save_chunks_batch()` raises RuntimeError on HTTP errors, no silent swallowing
2. Read `full_pass.py` — `delete_user_chunks()` raises on failures
3. Read `full_pass.py` — `run_full_pass_pipeline()` has no try/except (errors propagate naturally)
4. Read `streaming_import.py` — `trigger_full_pass()` TimeoutError handler updates DB with full_pass_status='failed'
5. Read `fact_extractor.py` — `extract_facts_parallel` uses concurrency=5 (not 10)
6. Read `fact_extractor.py` — `_extract_with_retry()` implements exponential backoff with jitter
7. Read `memory_generator.py` — `_is_placeholder_memory()` validates content before accepting
8. Read `memory_generator.py` — `generate_memory_section()` retries on placeholder content
</verification>

<success_criteria>
- Chunk saves raise exceptions on HTTP errors (not swallowed)
- Fact extraction retries 3x with exponential backoff on API errors
- Fact extraction concurrency reduced to 5
- Memory generation validates output and retries on placeholder content
- Fallback memory marked with [FALLBACK] prefix
- All trigger_full_pass() failure paths (timeout + exception) update full_pass_status='failed' in database
</success_criteria>

<output>
After completion, create `.planning/phases/01-pipeline-reliability/01-01-SUMMARY.md`
</output>
