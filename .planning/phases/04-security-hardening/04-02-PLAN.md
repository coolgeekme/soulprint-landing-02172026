---
phase: 04-security-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/rate-limit.ts
  - app/api/chat/route.ts
  - app/api/import/process-server/route.ts
  - app/api/import/chunked-upload/route.ts
autonomous: true
user_setup:
  - service: upstash
    why: "Distributed rate limiting for serverless (Vercel edge)"
    env_vars:
      - name: UPSTASH_REDIS_URL
        source: "Upstash Console -> Create Database -> REST API URL"
      - name: UPSTASH_REDIS_TOKEN
        source: "Upstash Console -> Create Database -> REST API Token"

must_haves:
  truths:
    - "Rapid repeated requests from the same user return 429 Too Many Requests"
    - "429 responses include Retry-After header with seconds until reset"
    - "Different endpoints have appropriate rate limits (chat is stricter than reads)"
    - "Rate limiting is per-user (authenticated), not global"
  artifacts:
    - path: "lib/rate-limit.ts"
      provides: "Rate limiting utility with tiered limits"
      exports: ["checkRateLimit", "limits"]
    - path: "app/api/chat/route.ts"
      provides: "Chat endpoint with rate limiting"
      contains: "checkRateLimit"
    - path: "app/api/import/process-server/route.ts"
      provides: "Import endpoint with rate limiting"
      contains: "checkRateLimit"
  key_links:
    - from: "lib/rate-limit.ts"
      to: "@upstash/ratelimit"
      via: "Ratelimit.slidingWindow"
      pattern: "Ratelimit\\.slidingWindow"
    - from: "app/api/chat/route.ts"
      to: "lib/rate-limit.ts"
      via: "import checkRateLimit"
      pattern: "checkRateLimit"
---

<objective>
Add per-user rate limiting using @upstash/ratelimit with tiered limits for different endpoint categories (standard, expensive, burst). Integrate into the 3 most critical state-changing routes.

Purpose: Prevent abuse and DoS attacks on expensive AI and import endpoints. Rate limits are per-authenticated-user with proper 429 + Retry-After responses.
Output: Rate limiting utility at lib/rate-limit.ts, integrated into chat, import, and chunked-upload routes.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-security-hardening/04-RESEARCH.md
@app/api/chat/route.ts
@app/api/import/process-server/route.ts
@app/api/import/chunked-upload/route.ts
@lib/api/error-handler.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Upstash packages and create rate limiting utility</name>
  <files>lib/rate-limit.ts</files>
  <action>
1. Install packages: `npm install @upstash/ratelimit @upstash/redis`

2. Create `lib/rate-limit.ts` with tiered rate limits:

```typescript
import { Ratelimit } from "@upstash/ratelimit";
import { Redis } from "@upstash/redis";

// Lazy initialization - only create Redis connection when first used
// This prevents errors during build if env vars are missing
let redis: Redis | null = null;
function getRedis(): Redis {
  if (!redis) {
    redis = new Redis({
      url: process.env.UPSTASH_REDIS_URL!,
      token: process.env.UPSTASH_REDIS_TOKEN!,
    });
  }
  return redis;
}

// Tiered rate limits for different endpoint types
export const limits = {
  // Standard operations (memory queries, profile reads)
  standard: () => new Ratelimit({
    redis: getRedis(),
    limiter: Ratelimit.slidingWindow(60, "60 s"),  // 60 req/min
    prefix: "rl:standard",
  }),

  // Expensive operations (AI chat, soulprint generation, import)
  expensive: () => new Ratelimit({
    redis: getRedis(),
    limiter: Ratelimit.slidingWindow(20, "60 s"),  // 20 req/min
    prefix: "rl:expensive",
  }),

  // Upload operations (chunked upload - bursty but limited)
  upload: () => new Ratelimit({
    redis: getRedis(),
    limiter: Ratelimit.slidingWindow(100, "60 s"),  // 100 req/min (chunks are small, frequent)
    prefix: "rl:upload",
  }),
};

// Cache the Ratelimit instances (they're stateless, just config)
let _standard: Ratelimit | null = null;
let _expensive: Ratelimit | null = null;
let _upload: Ratelimit | null = null;

function getLimit(tier: 'standard' | 'expensive' | 'upload'): Ratelimit {
  switch (tier) {
    case 'standard':
      if (!_standard) _standard = limits.standard();
      return _standard;
    case 'expensive':
      if (!_expensive) _expensive = limits.expensive();
      return _expensive;
    case 'upload':
      if (!_upload) _upload = limits.upload();
      return _upload;
  }
}

/**
 * Check rate limit for a user. Returns a Response if rate limited, null if OK.
 *
 * Usage:
 *   const rateLimited = await checkRateLimit(userId, 'expensive');
 *   if (rateLimited) return rateLimited;
 */
export async function checkRateLimit(
  userId: string,
  tier: 'standard' | 'expensive' | 'upload' = 'standard'
): Promise<Response | null> {
  // Skip rate limiting if Upstash is not configured (dev/test)
  if (!process.env.UPSTASH_REDIS_URL || !process.env.UPSTASH_REDIS_TOKEN) {
    return null;
  }

  try {
    const limiter = getLimit(tier);
    const { success, reset, remaining } = await limiter.limit(userId);

    if (!success) {
      const retryAfter = Math.ceil((reset - Date.now()) / 1000);
      return new Response(
        JSON.stringify({ error: 'Too many requests', code: 'RATE_LIMITED' }),
        {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'Retry-After': retryAfter.toString(),
            'X-RateLimit-Remaining': '0',
            'X-RateLimit-Reset': reset.toString(),
          },
        }
      );
    }

    return null; // Not rate limited
  } catch (error) {
    // If rate limiting fails (Redis down), allow the request through
    // Security: fail-open for availability, other layers still protect
    console.error('[RateLimit] Check failed, allowing request:', error);
    return null;
  }
}
```

Key design decisions:
- Lazy Redis initialization prevents build failures when env vars are missing
- Fail-open: if Upstash is down, requests pass through (availability over strictness)
- Per-user via userId (not IP), so logged-in users get independent limits
- checkRateLimit returns a Response or null for ergonomic usage pattern
- Skip rate limiting in dev/test if Upstash env vars not set
  </action>
  <verify>
Run `npm run build` to confirm no TypeScript errors. Check that `lib/rate-limit.ts` exists and exports `checkRateLimit` and `limits`.
  </verify>
  <done>Rate limiting utility created with 3 tiers (standard: 60/min, expensive: 20/min, upload: 100/min) and ergonomic checkRateLimit helper.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate rate limiting into critical API routes</name>
  <files>app/api/chat/route.ts, app/api/import/process-server/route.ts, app/api/import/chunked-upload/route.ts</files>
  <action>
Add rate limiting to the 3 most critical state-changing routes. Insert the check AFTER auth (need userId) but BEFORE any expensive operations.

**For each route, add these 2 things:**

1. Import at top: `import { checkRateLimit } from '@/lib/rate-limit';`
2. Add check after auth, before processing:
```typescript
// Rate limit check
const rateLimited = await checkRateLimit(user.id, 'TIER');
if (rateLimited) return rateLimited;
```

**Specific integrations:**

a) `app/api/chat/route.ts` - POST handler, tier: `'expensive'`
   Insert after the auth check block (after `if (authError || !user)`) and before `const body = await request.json();`

b) `app/api/import/process-server/route.ts` - POST handler, tier: `'expensive'`
   Insert after the userId is determined (after both auth paths resolve userId) and before the processing logic begins.
   Note: This route has two auth paths (internal X-Internal-User-Id header and normal auth). Add rate limiting only for the normal auth path (internal calls are trusted).

c) `app/api/import/chunked-upload/route.ts` - POST handler, tier: `'upload'`
   Insert after the auth check and before chunk processing logic.

Do NOT modify the response format or error handling patterns of these routes. Only add the rate limit check.
  </action>
  <verify>
Run `npm run build` to confirm no TypeScript errors. Grep for `checkRateLimit` in the 3 modified route files to confirm integration.
  </verify>
  <done>Rate limiting integrated into chat (expensive: 20/min), import processing (expensive: 20/min), and chunked upload (upload: 100/min) routes.</done>
</task>

</tasks>

<verification>
1. `npm run build` passes without errors
2. `lib/rate-limit.ts` exports checkRateLimit and limits
3. 3 route files import and call checkRateLimit
4. Each route uses the appropriate tier (expensive or upload)
5. Rate limit check happens after auth but before expensive operations
</verification>

<success_criteria>
- Rate limit utility handles missing env vars gracefully (returns null, no crash)
- Rate limit utility handles Redis failures gracefully (fail-open)
- 429 responses include Retry-After header
- Chat route uses 'expensive' tier (20 req/min)
- Import route uses 'expensive' tier (20 req/min)
- Chunked upload uses 'upload' tier (100 req/min)
- Existing route behavior unchanged when not rate limited
</success_criteria>

<output>
After completion, create `.planning/phases/04-security-hardening/04-02-SUMMARY.md`
</output>
