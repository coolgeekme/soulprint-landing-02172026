---
phase: 04-cost-quality-measurement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rlm-service/processors/full_pass.py
  - rlm-service/processors/fact_extractor.py
  - rlm-service/processors/memory_generator.py
  - rlm-service/processors/embedding_generator.py
  - rlm-service/processors/v2_regenerator.py
  - rlm-service/processors/cost_tracker.py
  - app/api/admin/import-costs/route.ts
autonomous: true

must_haves:
  truths:
    - "Per-user import cost (LLM input/output tokens + embedding count) is accumulated during full pass and saved to user_profiles"
    - "Admin can view import costs per user via /api/admin/import-costs endpoint"
    - "Embedding cost verified under $0.10 per user import in pipeline logs"
  artifacts:
    - path: "rlm-service/processors/cost_tracker.py"
      provides: "CostTracker class that accumulates token counts and computes dollar costs"
      contains: "class CostTracker"
    - path: "app/api/admin/import-costs/route.ts"
      provides: "Admin endpoint returning per-user import cost data"
      exports: ["GET"]
  key_links:
    - from: "rlm-service/processors/fact_extractor.py"
      to: "rlm-service/processors/cost_tracker.py"
      via: "CostTracker.record_llm_call() after each Anthropic response"
      pattern: "tracker\\.record_llm_call"
    - from: "rlm-service/processors/full_pass.py"
      to: "rlm-service/processors/cost_tracker.py"
      via: "CostTracker instantiated at pipeline start, saved to DB at end"
      pattern: "CostTracker|import_cost"
    - from: "app/api/admin/import-costs/route.ts"
      to: "user_profiles.import_cost_json"
      via: "Supabase SELECT"
      pattern: "import_cost_json"
---

<objective>
Instrument the full pass pipeline with per-user cost tracking and expose via admin endpoint.

Purpose: Requirements COST-01 and VSRC-04 need import costs tracked and verified under $0.10/user. Currently no token usage is captured during the full pass pipeline. This plan adds a CostTracker that accumulates LLM tokens and embedding calls across all pipeline steps, saves the cost breakdown to user_profiles, and exposes it via an admin API.

Output: CostTracker module, instrumented pipeline processors, admin cost endpoint
</objective>

<execution_context>
@/home/drewpullen/.claude/get-shit-done/workflows/execute-plan.md
@/home/drewpullen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-vector-infrastructure/02-01-SUMMARY.md
@rlm-service/processors/full_pass.py
@rlm-service/processors/fact_extractor.py
@rlm-service/processors/embedding_generator.py
@rlm-service/processors/memory_generator.py
@rlm-service/processors/v2_regenerator.py
@app/api/admin/metrics/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CostTracker module and instrument all pipeline processors</name>
  <files>
    rlm-service/processors/cost_tracker.py
    rlm-service/processors/full_pass.py
    rlm-service/processors/fact_extractor.py
    rlm-service/processors/memory_generator.py
    rlm-service/processors/embedding_generator.py
    rlm-service/processors/v2_regenerator.py
  </files>
  <action>
    Create `rlm-service/processors/cost_tracker.py` with a `CostTracker` class:

    ```python
    class CostTracker:
        """Accumulates token usage and computes dollar costs during a full pass pipeline."""

        # Pricing per 1M tokens (as of 2025, Haiku 4.5 on Anthropic API)
        HAIKU_INPUT_COST_PER_M = 1.00   # $1.00 per 1M input tokens
        HAIKU_OUTPUT_COST_PER_M = 5.00  # $5.00 per 1M output tokens
        # Titan Embed v2 pricing (AWS Bedrock)
        TITAN_EMBED_COST_PER_M = 0.02   # $0.02 per 1M input tokens (no output)
    ```

    The class should track:
    - `llm_input_tokens: int` (total across all Haiku calls)
    - `llm_output_tokens: int` (total across all Haiku calls)
    - `llm_call_count: int`
    - `embedding_input_tokens: int` (estimated from text length / 4)
    - `embedding_call_count: int`

    Methods:
    - `record_llm_call(response)` -- takes an Anthropic API response, extracts `response.usage.input_tokens` and `response.usage.output_tokens`, increments counters
    - `record_embedding(text_length: int)` -- records one embedding call, estimates tokens as `text_length // 4`
    - `get_summary() -> dict` -- returns JSON-serializable dict with all counts plus computed costs:
      - `llm_cost_usd`: `(llm_input_tokens * HAIKU_INPUT_COST_PER_M + llm_output_tokens * HAIKU_OUTPUT_COST_PER_M) / 1_000_000`
      - `embedding_cost_usd`: `(embedding_input_tokens * TITAN_EMBED_COST_PER_M) / 1_000_000`
      - `total_cost_usd`: sum of above
      - All token counts and call counts

    Then instrument each processor:

    **fact_extractor.py:**
    - Modify `extract_facts_from_chunk()` to accept optional `cost_tracker: CostTracker = None` parameter
    - After `response = await anthropic_client.messages.create(...)`, add `if cost_tracker: cost_tracker.record_llm_call(response)`
    - Thread cost_tracker through `_extract_with_retry()` and `extract_facts_parallel()` (add parameter, pass down)
    - Also instrument the `hierarchical_reduce()` function's Haiku calls

    **memory_generator.py:**
    - Modify `generate_memory_section()` to accept optional `cost_tracker: CostTracker = None` parameter
    - After each `response = await anthropic_client.messages.create(...)`, add `if cost_tracker: cost_tracker.record_llm_call(response)`

    **embedding_generator.py:**
    - Modify `embed_text()` to accept optional `cost_tracker: CostTracker = None` parameter
    - After generating embedding, add `if cost_tracker: cost_tracker.record_embedding(len(text))`
    - Thread through `embed_batch()` and `generate_embeddings_for_chunks()` (add parameter, pass down)

    **v2_regenerator.py:**
    - Modify `regenerate_sections_v2()` to accept optional `cost_tracker: CostTracker = None` parameter
    - After each `response = await anthropic_client.messages.create(...)`, add `if cost_tracker: cost_tracker.record_llm_call(response)`

    **full_pass.py:**
    - Import CostTracker: `from processors.cost_tracker import CostTracker`
    - Create tracker at start of `run_full_pass_pipeline()`: `tracker = CostTracker()`
    - Pass tracker to all pipeline steps: `extract_facts_parallel(chunks, client, cost_tracker=tracker)`, `hierarchical_reduce(consolidated, client, cost_tracker=tracker)`, `generate_memory_section(reduced, client, cost_tracker=tracker)`, `generate_embeddings_for_chunks(user_id, cost_tracker=tracker)`, `regenerate_sections_v2(conversations_light, memory_md, client, cost_tracker=tracker)`
    - After Step 9 (V2 regen) and before final print, save cost to DB:
      ```python
      cost_summary = tracker.get_summary()
      print(f"[FullPass] Cost summary: ${cost_summary['total_cost_usd']:.4f} "
            f"(LLM: ${cost_summary['llm_cost_usd']:.4f}, Embed: ${cost_summary['embedding_cost_usd']:.4f})")
      await update_user_profile(user_id, {"import_cost_json": json.dumps(cost_summary)})
      ```
    - The return type of run_full_pass_pipeline stays the same (returns memory_md string)

    IMPORTANT: All cost_tracker parameters are optional with default None. This means the pipeline works identically when called without a tracker (backwards compatible). Processors only call tracker methods when tracker is not None.

    NOTE: The `import_cost_json` column may not exist yet in Supabase. The upsert will be best-effort via update_user_profile() which already has error handling. The column needs to be added manually as a TEXT column in Supabase SQL Editor. Document this as user setup.
  </action>
  <verify>
    1. `python3 -c "import ast; ast.parse(open('rlm-service/processors/cost_tracker.py').read()); print('Syntax OK')"`
    2. `python3 -c "import ast; ast.parse(open('rlm-service/processors/full_pass.py').read()); print('Syntax OK')"`
    3. `python3 -c "import ast; ast.parse(open('rlm-service/processors/fact_extractor.py').read()); print('Syntax OK')"`
    4. `python3 -c "import ast; ast.parse(open('rlm-service/processors/memory_generator.py').read()); print('Syntax OK')"`
    5. `python3 -c "import ast; ast.parse(open('rlm-service/processors/embedding_generator.py').read()); print('Syntax OK')"`
    6. `python3 -c "import ast; ast.parse(open('rlm-service/processors/v2_regenerator.py').read()); print('Syntax OK')"`
    7. grep confirms `CostTracker` class exists in cost_tracker.py
    8. grep confirms `cost_tracker` parameter in extract_facts_parallel, generate_memory_section, generate_embeddings_for_chunks, regenerate_sections_v2
    9. grep confirms `import_cost_json` saved in full_pass.py
  </verify>
  <done>
    CostTracker module exists with pricing constants for Haiku 4.5 and Titan Embed v2. All 5 pipeline processors accept optional cost_tracker parameter and record usage. Full pass pipeline creates tracker, threads it through all steps, and saves cost summary JSON to user_profiles.import_cost_json on completion. Pipeline remains backwards compatible (tracker is optional).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create admin import-costs endpoint</name>
  <files>
    app/api/admin/import-costs/route.ts
  </files>
  <action>
    Create `app/api/admin/import-costs/route.ts` following the pattern from `app/api/admin/metrics/route.ts`:

    1. Import NextResponse, createClient from supabase-js, createClient as createServerClient from @/lib/supabase/server
    2. Define ADMIN_EMAILS array (same as metrics: `['drew@archeforge.com', 'drewspatterson@gmail.com']`)
    3. Implement GET handler:
       - Auth check via `createServerClient()` + `getUser()`
       - Admin email check (403 if not admin)
       - Create admin Supabase client with service role key
       - Query: `adminClient.from('user_profiles').select('user_id, import_cost_json, full_pass_status, full_pass_completed_at').not('import_cost_json', 'is', null).order('full_pass_completed_at', { ascending: false }).limit(50)`
       - For each row, parse import_cost_json (it's a TEXT column containing JSON string), extract total_cost_usd, llm_cost_usd, embedding_cost_usd, llm_call_count, embedding_call_count
       - Return JSON response:
         ```typescript
         {
           timestamp: new Date().toISOString(),
           users: [
             {
               user_id: string, // truncated to first 8 chars for privacy
               total_cost_usd: number,
               llm_cost_usd: number,
               embedding_cost_usd: number,
               llm_calls: number,
               embedding_calls: number,
               full_pass_status: string,
               completed_at: string | null,
             }
           ],
           summary: {
             total_imports: number,
             avg_cost_usd: number,
             max_cost_usd: number,
             min_cost_usd: number,
             all_under_budget: boolean, // true if all users < $0.10
           }
         }
         ```
       - Wrap in try/catch, return 500 on errors (same pattern as metrics)

    Use proper TypeScript types. No `any` types. Parse import_cost_json safely with try/catch for JSON.parse.
  </action>
  <verify>
    1. `npm run build` succeeds
    2. grep confirms ADMIN_EMAILS in import-costs route
    3. grep confirms import_cost_json query in route
    4. grep confirms all_under_budget in response
  </verify>
  <done>
    Admin endpoint at /api/admin/import-costs returns per-user import cost breakdown with summary statistics including budget verification (all_under_budget flag). Only accessible to admin emails. Parses import_cost_json from user_profiles.
  </done>
</task>

</tasks>

<verification>
1. All Python files pass syntax check (ast.parse)
2. Next.js build succeeds (`npm run build`)
3. CostTracker correctly computes costs: manual check that `CostTracker` with 100K input tokens, 10K output tokens at Haiku 4.5 rates = $0.15 (0.10 input + 0.05 output)
4. All processors accept optional cost_tracker parameter (backwards compatible)
5. Full pass saves cost summary to database
6. Admin endpoint returns cost data with budget verification
</verification>

<success_criteria>
- CostTracker module with Haiku 4.5 ($1/$5 per 1M I/O) and Titan Embed v2 ($0.02 per 1M) pricing
- All 5 pipeline processors instrumented (fact_extractor, memory_generator, embedding_generator, v2_regenerator, full_pass)
- Cost summary saved to user_profiles.import_cost_json after each full pass
- Admin endpoint at /api/admin/import-costs showing per-user costs and budget verification
- All existing functionality preserved (optional tracker parameter)
</success_criteria>

<output>
After completion, create `.planning/phases/04-cost-quality-measurement/04-01-SUMMARY.md`
</output>
