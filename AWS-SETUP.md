# AWS Bedrock Setup - 100% AWS, Zero Data Leaks

**All AI processing now runs on AWS Bedrock** - no data goes to OpenAI, Anthropic, Google, or any third party.

## Required AWS Bedrock Models

Enable these in AWS Console ‚Üí Bedrock ‚Üí Model Access:

### 1. Chat Model: Claude 3.5 Haiku
- **Model ID**: `anthropic.claude-3-5-haiku-20241022-v2:0`
- **Use**: All chat, SoulPrint generation, avatar prompts
- **Cost**: ~$0.80/$4 per million tokens (input/output)
- **Why**: Best balance of speed, quality, and cost

### 2. Embeddings Model: Titan Embeddings G1
- **Model ID**: `amazon.titan-embed-text-v1`
- **Use**: Vector embeddings for semantic memory search
- **Dimensions**: 1536 (same as OpenAI)
- **Cost**: ~$0.10 per million tokens
- **Why**: Native AWS, cheap, perfect for RAG

## Setup Steps

### 1. No Manual Model Enablement Needed! ‚ú®
**As of 2026, AWS Bedrock models are auto-enabled on first use!**

Simply invoke the models via API and they'll activate automatically:
- Claude models may require use case details on first invocation
- AWS Marketplace models need one invocation by admin to enable account-wide

No need to manually enable in the console anymore. Just set up credentials and start using!

### 2. Create IAM User/Role
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "BedrockFullAccess",
      "Effect": "Allow",
      "Action": [
        "bedrock:InvokeModel",
        "bedrock:InvokeModelWithResponseStream"
      ],
      "Resource": "*"
    }
  ]
}
```

### 3. Set Environment Variables
```bash
AWS_REGION=us-east-1
BEDROCK_MODEL_ID=anthropic.claude-3-5-haiku-20241022-v2:0
BEDROCK_EMBEDDING_MODEL_ID=amazon.titan-embed-text-v1
AWS_ACCESS_KEY_ID=your_key_here
AWS_SECRET_ACCESS_KEY=your_secret_here
```

### 4. Test & Auto-Enable Models
```bash
cd Soulprint-roughdraft

# Test chat model (auto-enables Claude Haiku on first run)
npx tsx scripts/test-bedrock.ts

# Test embeddings (auto-enables Titan Embeddings on first run)
npx tsx scripts/test-embeddings.ts
```

**Note**: First run may prompt for Anthropic use case details. Simply provide your use case and the model will be enabled instantly.

## Data Privacy Guarantee

‚úÖ **Chat**: AWS Bedrock (Claude Haiku)  
‚úÖ **Embeddings**: AWS Bedrock (Titan)  
‚úÖ **SoulPrint Generation**: AWS Bedrock (Claude Haiku)  
‚úÖ **Avatar Prompts**: AWS Bedrock (Claude Haiku)  

‚ùå **Removed**: OpenAI, Google Gemini, Anthropic Direct API  
‚ùå **Removed**: All third-party LLM services

**Result**: 100% of your user data stays within your AWS account. Zero external API calls for AI processing.

## Cost Comparison

**Old Setup** (OpenAI):
- Embeddings: $0.02/million tokens
- Chat (GPT-4o-mini): $0.15/$0.60 per million

**New Setup** (AWS Bedrock):
- Embeddings: $0.10/million tokens (5x but stays in AWS)
- Chat (Claude Haiku): $0.80/$4 per million (comparable to GPT-4)

**Privacy Value**: Priceless üîí

## Compliance Benefits

- ‚úÖ GDPR compliant (data stays in your AWS region)
- ‚úÖ HIPAA eligible (with AWS BAA)
- ‚úÖ SOC 2 ready (AWS certified infrastructure)
- ‚úÖ No third-party data sharing
- ‚úÖ Full audit trail in CloudWatch

## Next Steps

1. ~~Enable models in AWS Console~~ **Not needed! Auto-enabled on first use**
2. Update `.env.local` with AWS credentials
3. Test with `scripts/test-bedrock.ts` (auto-enables models)
4. Deploy to Vercel with new env vars
5. Enjoy secure, private AI! üöÄ

**Time to deploy: ~10 minutes** (down from 15+ with manual model enablement)
